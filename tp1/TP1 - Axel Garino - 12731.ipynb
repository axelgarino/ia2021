{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP1 - Axel Garino -  12731\n",
    "### Dataset: Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aclaro que voy a ir importando librerias mediante las vaya utilizando, de modo que me sea más fácil entender el tp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOY A TRABAJAR CON PANDAS EL PUNTO 1 DEBIDO A QUE ME ES MÁS FACIL VISUALIZAR LOS DATOS, \n",
    "# PARA ESTO UTILIZO EL DATASET CANCER QUE ESTÁ EN FORMATO.CVS\n",
    "\n",
    "import pandas as pd \n",
    "cancer = pd.read_csv(\"cancerData.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Visualizar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0      842302         M        17.99         10.38          122.80     1001.0   \n",
       "1      842517         M        20.57         17.77          132.90     1326.0   \n",
       "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3    84348301         M        11.42         20.38           77.58      386.1   \n",
       "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
       "..        ...       ...          ...           ...             ...        ...   \n",
       "564    926424         M        21.56         22.39          142.00     1479.0   \n",
       "565    926682         M        20.13         28.25          131.20     1261.0   \n",
       "566    926954         M        16.60         28.08          108.30      858.1   \n",
       "567    927241         M        20.60         29.33          140.10     1265.0   \n",
       "568     92751         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0    ...          17.33           184.60      2019.0           0.16220   \n",
       "1    ...          23.41           158.80      1956.0           0.12380   \n",
       "2    ...          25.53           152.50      1709.0           0.14440   \n",
       "3    ...          26.50            98.87       567.7           0.20980   \n",
       "4    ...          16.67           152.20      1575.0           0.13740   \n",
       "..   ...            ...              ...         ...               ...   \n",
       "564  ...          26.40           166.10      2027.0           0.14100   \n",
       "565  ...          38.25           155.00      1731.0           0.11660   \n",
       "566  ...          34.12           126.70      1124.0           0.11390   \n",
       "567  ...          39.42           184.60      1821.0           0.16500   \n",
       "568  ...          30.37            59.16       268.6           0.08996   \n",
       "\n",
       "     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0              0.66560           0.7119                0.2654          0.4601   \n",
       "1              0.18660           0.2416                0.1860          0.2750   \n",
       "2              0.42450           0.4504                0.2430          0.3613   \n",
       "3              0.86630           0.6869                0.2575          0.6638   \n",
       "4              0.20500           0.4000                0.1625          0.2364   \n",
       "..                 ...              ...                   ...             ...   \n",
       "564            0.21130           0.4107                0.2216          0.2060   \n",
       "565            0.19220           0.3215                0.1628          0.2572   \n",
       "566            0.30940           0.3403                0.1418          0.2218   \n",
       "567            0.86810           0.9387                0.2650          0.4087   \n",
       "568            0.06444           0.0000                0.0000          0.2871   \n",
       "\n",
       "     fractal_dimension_worst  Unnamed: 32  \n",
       "0                    0.11890          NaN  \n",
       "1                    0.08902          NaN  \n",
       "2                    0.08758          NaN  \n",
       "3                    0.17300          NaN  \n",
       "4                    0.07678          NaN  \n",
       "..                       ...          ...  \n",
       "564                  0.07115          NaN  \n",
       "565                  0.06637          NaN  \n",
       "566                  0.07820          NaN  \n",
       "567                  0.12400          NaN  \n",
       "568                  0.07039          NaN  \n",
       "\n",
       "[569 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n"
     ]
    }
   ],
   "source": [
    "cancer.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Podemos ver que todas nuestras variables son categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "diagnosis                    0\n",
       "radius_mean                  0\n",
       "texture_mean                 0\n",
       "perimeter_mean               0\n",
       "area_mean                    0\n",
       "smoothness_mean              0\n",
       "compactness_mean             0\n",
       "concavity_mean               0\n",
       "concave points_mean          0\n",
       "symmetry_mean                0\n",
       "fractal_dimension_mean       0\n",
       "radius_se                    0\n",
       "texture_se                   0\n",
       "perimeter_se                 0\n",
       "area_se                      0\n",
       "smoothness_se                0\n",
       "compactness_se               0\n",
       "concavity_se                 0\n",
       "concave points_se            0\n",
       "symmetry_se                  0\n",
       "fractal_dimension_se         0\n",
       "radius_worst                 0\n",
       "texture_worst                0\n",
       "perimeter_worst              0\n",
       "area_worst                   0\n",
       "smoothness_worst             0\n",
       "compactness_worst            0\n",
       "concavity_worst              0\n",
       "concave points_worst         0\n",
       "symmetry_worst               0\n",
       "fractal_dimension_worst      0\n",
       "Unnamed: 32                569\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vemos si hay columnas con valores nulos\n",
    "\n",
    "cancer.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cuantos valores hay de cada columna</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diagnosis</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_mean</th>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_mean</th>\n",
       "      <td>479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_mean</th>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_mean</th>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_mean</th>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_mean</th>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_mean</th>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_mean</th>\n",
       "      <td>542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_mean</th>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_se</th>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_se</th>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_se</th>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_se</th>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_se</th>\n",
       "      <td>547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_se</th>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_se</th>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_se</th>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_se</th>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <td>545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_worst</th>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_worst</th>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_worst</th>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_worst</th>\n",
       "      <td>544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_worst</th>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_worst</th>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_worst</th>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_worst</th>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_worst</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <td>535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 32</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Cuantos valores hay de cada columna\n",
       "id                                                       569\n",
       "diagnosis                                                  2\n",
       "radius_mean                                              456\n",
       "texture_mean                                             479\n",
       "perimeter_mean                                           522\n",
       "area_mean                                                539\n",
       "smoothness_mean                                          474\n",
       "compactness_mean                                         537\n",
       "concavity_mean                                           537\n",
       "concave points_mean                                      542\n",
       "symmetry_mean                                            432\n",
       "fractal_dimension_mean                                   499\n",
       "radius_se                                                540\n",
       "texture_se                                               519\n",
       "perimeter_se                                             533\n",
       "area_se                                                  528\n",
       "smoothness_se                                            547\n",
       "compactness_se                                           541\n",
       "concavity_se                                             533\n",
       "concave points_se                                        507\n",
       "symmetry_se                                              498\n",
       "fractal_dimension_se                                     545\n",
       "radius_worst                                             457\n",
       "texture_worst                                            511\n",
       "perimeter_worst                                          514\n",
       "area_worst                                               544\n",
       "smoothness_worst                                         411\n",
       "compactness_worst                                        529\n",
       "concavity_worst                                          539\n",
       "concave points_worst                                     492\n",
       "symmetry_worst                                           500\n",
       "fractal_dimension_worst                                  535\n",
       "Unnamed: 32                                                0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {}\n",
    "for i in list(cancer.columns):\n",
    "    dict[i] = cancer[i].value_counts().shape[0]\n",
    "\n",
    "pd.DataFrame(dict,index=[\"Cuantos valores hay de cada columna\"]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.037183e+07</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>...</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.250206e+08</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>...</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.692180e+05</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>...</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.060240e+05</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.813129e+06</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>...</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count  5.690000e+02   569.000000    569.000000      569.000000   569.000000   \n",
       "mean   3.037183e+07    14.127292     19.289649       91.969033   654.889104   \n",
       "std    1.250206e+08     3.524049      4.301036       24.298981   351.914129   \n",
       "min    8.670000e+03     6.981000      9.710000       43.790000   143.500000   \n",
       "25%    8.692180e+05    11.700000     16.170000       75.170000   420.300000   \n",
       "50%    9.060240e+05    13.370000     18.840000       86.240000   551.100000   \n",
       "75%    8.813129e+06    15.780000     21.800000      104.100000   782.700000   \n",
       "max    9.113205e+08    28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       symmetry_mean  ...  texture_worst  perimeter_worst   area_worst  \\\n",
       "count     569.000000  ...     569.000000       569.000000   569.000000   \n",
       "mean        0.181162  ...      25.677223       107.261213   880.583128   \n",
       "std         0.027414  ...       6.146258        33.602542   569.356993   \n",
       "min         0.106000  ...      12.020000        50.410000   185.200000   \n",
       "25%         0.161900  ...      21.080000        84.110000   515.300000   \n",
       "50%         0.179200  ...      25.410000        97.660000   686.500000   \n",
       "75%         0.195700  ...      29.720000       125.400000  1084.000000   \n",
       "max         0.304000  ...      49.540000       251.200000  4254.000000   \n",
       "\n",
       "       smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "count        569.000000         569.000000       569.000000   \n",
       "mean           0.132369           0.254265         0.272188   \n",
       "std            0.022832           0.157336         0.208624   \n",
       "min            0.071170           0.027290         0.000000   \n",
       "25%            0.116600           0.147200         0.114500   \n",
       "50%            0.131300           0.211900         0.226700   \n",
       "75%            0.146000           0.339100         0.382900   \n",
       "max            0.222600           1.058000         1.252000   \n",
       "\n",
       "       concave points_worst  symmetry_worst  fractal_dimension_worst  \\\n",
       "count            569.000000      569.000000               569.000000   \n",
       "mean               0.114606        0.290076                 0.083946   \n",
       "std                0.065732        0.061867                 0.018061   \n",
       "min                0.000000        0.156500                 0.055040   \n",
       "25%                0.064930        0.250400                 0.071460   \n",
       "50%                0.099930        0.282200                 0.080040   \n",
       "75%                0.161400        0.317900                 0.092080   \n",
       "max                0.291000        0.663800                 0.207500   \n",
       "\n",
       "       Unnamed: 32  \n",
       "count          0.0  \n",
       "mean           NaN  \n",
       "std            NaN  \n",
       "min            NaN  \n",
       "25%            NaN  \n",
       "50%            NaN  \n",
       "75%            NaN  \n",
       "max            NaN  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ver sumarizaciones\n",
    "cancer.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    357\n",
       "M    212\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vemos cuantos cancer Malignos M y Benignos B hay en nuestro dataset\n",
    "resultado = cancer[\"diagnosis\"].value_counts()\n",
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Grafico \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar([\"Benignos\",\"Malignos\"], resultado, color='blue')\n",
    "plt.ylabel(\"Cantidad\")\n",
    "plt.title(\"Cantidad de cancer Maligno/Benigno\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Tambien encontré una forma de hacerlo mas sencillo\n",
    "cancer.diagnosis.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AHORA VAMOS A UTILIZAR EL DATASET DE CANCER DE LA LIBRERIA SKLEARN\n",
    "\n",
    "# 2) Dividir entre entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 0\n",
      " 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 0 0 1\n",
      " 1 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 1 0 1 0\n",
      " 1 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 1 1\n",
      " 1 1 0 1 0 1 1 1 0 1 1 1 0 0 1 1 0 0 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Divido el dataset en datos de entrenamiento y test con la libreria sklearn. 70% entrenamiento - 30% test.\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "X, y = cancer.data, cancer.target\n",
    "\n",
    "# Dividimos el conjunto en train, test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=80, test_size=0.3)\n",
    "\n",
    "# vemos los resultados de la mezcla...\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Entrenar un modelo simple, ej: kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probamos entrenar...\n",
    "from sklearn import neighbors\n",
    "\n",
    "clf_sk = neighbors.KNeighborsClassifier(n_neighbors=3, p=1) #Siempre elijo cantidad de vecinos impar\n",
    "clf_sk.fit(X_train,y_train)\n",
    "y_hat = clf_sk.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de aciertos:  0.9239766081871345\n"
     ]
    }
   ],
   "source": [
    "# Ver métricas de rendimiento\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy =accuracy_score(y_true=y_test, y_pred=y_hat)\n",
    "print('Tasa de aciertos: ', accuracy_score(y_true=y_test, y_pred=y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x12b4ae41040>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Relacion entre las falsos positivos y negativos\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(clf_sk, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Normalizar características ¿mejora haciendo eso?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.160691</td>\n",
       "      <td>0.659877</td>\n",
       "      <td>1.091168</td>\n",
       "      <td>1.097729</td>\n",
       "      <td>-0.151381</td>\n",
       "      <td>-0.165207</td>\n",
       "      <td>0.275593</td>\n",
       "      <td>0.464458</td>\n",
       "      <td>-0.457459</td>\n",
       "      <td>-0.804410</td>\n",
       "      <td>...</td>\n",
       "      <td>1.232853</td>\n",
       "      <td>0.984021</td>\n",
       "      <td>1.070652</td>\n",
       "      <td>1.158125</td>\n",
       "      <td>0.639449</td>\n",
       "      <td>-0.176398</td>\n",
       "      <td>0.541403</td>\n",
       "      <td>0.334472</td>\n",
       "      <td>0.340277</td>\n",
       "      <td>-0.438374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.089997</td>\n",
       "      <td>-0.981537</td>\n",
       "      <td>-0.135072</td>\n",
       "      <td>-0.201970</td>\n",
       "      <td>-0.091825</td>\n",
       "      <td>-0.538184</td>\n",
       "      <td>-0.559796</td>\n",
       "      <td>-0.309995</td>\n",
       "      <td>1.116319</td>\n",
       "      <td>-0.629761</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.264770</td>\n",
       "      <td>-0.622481</td>\n",
       "      <td>-0.268163</td>\n",
       "      <td>-0.366338</td>\n",
       "      <td>-0.571946</td>\n",
       "      <td>-0.522636</td>\n",
       "      <td>-0.609859</td>\n",
       "      <td>-0.224541</td>\n",
       "      <td>0.092437</td>\n",
       "      <td>-0.821733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.258571</td>\n",
       "      <td>0.189160</td>\n",
       "      <td>1.118671</td>\n",
       "      <td>1.169698</td>\n",
       "      <td>-0.502487</td>\n",
       "      <td>-0.871113</td>\n",
       "      <td>-0.140265</td>\n",
       "      <td>0.216515</td>\n",
       "      <td>-0.992092</td>\n",
       "      <td>-1.817651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.724376</td>\n",
       "      <td>-0.196301</td>\n",
       "      <td>0.600096</td>\n",
       "      <td>0.571538</td>\n",
       "      <td>-0.321014</td>\n",
       "      <td>-0.877043</td>\n",
       "      <td>-0.263884</td>\n",
       "      <td>0.209331</td>\n",
       "      <td>-0.531993</td>\n",
       "      <td>-1.467073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.951337</td>\n",
       "      <td>0.374520</td>\n",
       "      <td>0.981156</td>\n",
       "      <td>0.801059</td>\n",
       "      <td>1.039749</td>\n",
       "      <td>1.115757</td>\n",
       "      <td>1.107309</td>\n",
       "      <td>1.376466</td>\n",
       "      <td>0.592981</td>\n",
       "      <td>-0.195911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.825674</td>\n",
       "      <td>-0.061454</td>\n",
       "      <td>0.710649</td>\n",
       "      <td>0.680902</td>\n",
       "      <td>0.436108</td>\n",
       "      <td>0.592112</td>\n",
       "      <td>0.366121</td>\n",
       "      <td>0.534698</td>\n",
       "      <td>-0.699365</td>\n",
       "      <td>-0.368073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005165</td>\n",
       "      <td>0.323302</td>\n",
       "      <td>-0.000700</td>\n",
       "      <td>-0.119340</td>\n",
       "      <td>-0.496947</td>\n",
       "      <td>0.087811</td>\n",
       "      <td>-0.490605</td>\n",
       "      <td>-0.471257</td>\n",
       "      <td>-1.157753</td>\n",
       "      <td>-0.413529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027206</td>\n",
       "      <td>0.296471</td>\n",
       "      <td>0.121037</td>\n",
       "      <td>-0.103699</td>\n",
       "      <td>-0.710391</td>\n",
       "      <td>0.548754</td>\n",
       "      <td>-0.125310</td>\n",
       "      <td>0.275582</td>\n",
       "      <td>-0.585101</td>\n",
       "      <td>-0.302166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>-0.750686</td>\n",
       "      <td>0.286718</td>\n",
       "      <td>-0.583370</td>\n",
       "      <td>-0.738536</td>\n",
       "      <td>3.186552</td>\n",
       "      <td>3.282378</td>\n",
       "      <td>1.769602</td>\n",
       "      <td>1.371527</td>\n",
       "      <td>2.949883</td>\n",
       "      <td>4.763566</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.278674</td>\n",
       "      <td>0.169949</td>\n",
       "      <td>-0.253990</td>\n",
       "      <td>-0.535852</td>\n",
       "      <td>3.378066</td>\n",
       "      <td>3.837702</td>\n",
       "      <td>1.873911</td>\n",
       "      <td>2.095283</td>\n",
       "      <td>6.019687</td>\n",
       "      <td>4.883618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>-0.794188</td>\n",
       "      <td>0.152575</td>\n",
       "      <td>-0.830111</td>\n",
       "      <td>-0.733205</td>\n",
       "      <td>-0.787805</td>\n",
       "      <td>-1.142586</td>\n",
       "      <td>-1.030427</td>\n",
       "      <td>-1.086572</td>\n",
       "      <td>-0.664535</td>\n",
       "      <td>0.049430</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.870573</td>\n",
       "      <td>0.158295</td>\n",
       "      <td>-0.891508</td>\n",
       "      <td>-0.754248</td>\n",
       "      <td>-0.905079</td>\n",
       "      <td>-1.120667</td>\n",
       "      <td>-1.161721</td>\n",
       "      <td>-1.278819</td>\n",
       "      <td>-0.548086</td>\n",
       "      <td>-0.436726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>-0.636493</td>\n",
       "      <td>-0.064491</td>\n",
       "      <td>-0.664700</td>\n",
       "      <td>-0.626851</td>\n",
       "      <td>-0.538498</td>\n",
       "      <td>-0.683609</td>\n",
       "      <td>-0.774242</td>\n",
       "      <td>-0.882438</td>\n",
       "      <td>-1.056097</td>\n",
       "      <td>-0.346996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.598458</td>\n",
       "      <td>-0.081431</td>\n",
       "      <td>-0.640923</td>\n",
       "      <td>-0.571312</td>\n",
       "      <td>-0.160937</td>\n",
       "      <td>-0.424609</td>\n",
       "      <td>-0.602976</td>\n",
       "      <td>-0.677994</td>\n",
       "      <td>-0.583492</td>\n",
       "      <td>-0.228021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>-0.644649</td>\n",
       "      <td>-0.442529</td>\n",
       "      <td>-0.674130</td>\n",
       "      <td>-0.624452</td>\n",
       "      <td>0.291830</td>\n",
       "      <td>-0.930538</td>\n",
       "      <td>-0.811681</td>\n",
       "      <td>-0.842926</td>\n",
       "      <td>-0.359569</td>\n",
       "      <td>-0.730947</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.743454</td>\n",
       "      <td>0.166619</td>\n",
       "      <td>-0.801082</td>\n",
       "      <td>-0.665431</td>\n",
       "      <td>0.167870</td>\n",
       "      <td>-0.977584</td>\n",
       "      <td>-0.874020</td>\n",
       "      <td>-1.061809</td>\n",
       "      <td>0.486728</td>\n",
       "      <td>-1.006273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>-1.498108</td>\n",
       "      <td>-1.159581</td>\n",
       "      <td>-1.493325</td>\n",
       "      <td>-1.162084</td>\n",
       "      <td>-0.353596</td>\n",
       "      <td>-1.167870</td>\n",
       "      <td>-1.090460</td>\n",
       "      <td>-1.226448</td>\n",
       "      <td>-0.344509</td>\n",
       "      <td>0.577535</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.400501</td>\n",
       "      <td>-1.404923</td>\n",
       "      <td>-1.402315</td>\n",
       "      <td>-1.047044</td>\n",
       "      <td>-0.671453</td>\n",
       "      <td>-1.162517</td>\n",
       "      <td>-1.277949</td>\n",
       "      <td>-1.695760</td>\n",
       "      <td>-0.491759</td>\n",
       "      <td>-0.307659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0    1.160691  0.659877  1.091168  1.097729 -0.151381 -0.165207  0.275593   \n",
       "1   -0.089997 -0.981537 -0.135072 -0.201970 -0.091825 -0.538184 -0.559796   \n",
       "2    1.258571  0.189160  1.118671  1.169698 -0.502487 -0.871113 -0.140265   \n",
       "3    0.951337  0.374520  0.981156  0.801059  1.039749  1.115757  1.107309   \n",
       "4    0.005165  0.323302 -0.000700 -0.119340 -0.496947  0.087811 -0.490605   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "393 -0.750686  0.286718 -0.583370 -0.738536  3.186552  3.282378  1.769602   \n",
       "394 -0.794188  0.152575 -0.830111 -0.733205 -0.787805 -1.142586 -1.030427   \n",
       "395 -0.636493 -0.064491 -0.664700 -0.626851 -0.538498 -0.683609 -0.774242   \n",
       "396 -0.644649 -0.442529 -0.674130 -0.624452  0.291830 -0.930538 -0.811681   \n",
       "397 -1.498108 -1.159581 -1.493325 -1.162084 -0.353596 -1.167870 -1.090460   \n",
       "\n",
       "           7         8         9   ...        20        21        22  \\\n",
       "0    0.464458 -0.457459 -0.804410  ...  1.232853  0.984021  1.070652   \n",
       "1   -0.309995  1.116319 -0.629761  ... -0.264770 -0.622481 -0.268163   \n",
       "2    0.216515 -0.992092 -1.817651  ...  0.724376 -0.196301  0.600096   \n",
       "3    1.376466  0.592981 -0.195911  ...  0.825674 -0.061454  0.710649   \n",
       "4   -0.471257 -1.157753 -0.413529  ...  0.027206  0.296471  0.121037   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "393  1.371527  2.949883  4.763566  ... -0.278674  0.169949 -0.253990   \n",
       "394 -1.086572 -0.664535  0.049430  ... -0.870573  0.158295 -0.891508   \n",
       "395 -0.882438 -1.056097 -0.346996  ... -0.598458 -0.081431 -0.640923   \n",
       "396 -0.842926 -0.359569 -0.730947  ... -0.743454  0.166619 -0.801082   \n",
       "397 -1.226448 -0.344509  0.577535  ... -1.400501 -1.404923 -1.402315   \n",
       "\n",
       "           23        24        25        26        27        28        29  \n",
       "0    1.158125  0.639449 -0.176398  0.541403  0.334472  0.340277 -0.438374  \n",
       "1   -0.366338 -0.571946 -0.522636 -0.609859 -0.224541  0.092437 -0.821733  \n",
       "2    0.571538 -0.321014 -0.877043 -0.263884  0.209331 -0.531993 -1.467073  \n",
       "3    0.680902  0.436108  0.592112  0.366121  0.534698 -0.699365 -0.368073  \n",
       "4   -0.103699 -0.710391  0.548754 -0.125310  0.275582 -0.585101 -0.302166  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "393 -0.535852  3.378066  3.837702  1.873911  2.095283  6.019687  4.883618  \n",
       "394 -0.754248 -0.905079 -1.120667 -1.161721 -1.278819 -0.548086 -0.436726  \n",
       "395 -0.571312 -0.160937 -0.424609 -0.602976 -0.677994 -0.583492 -0.228021  \n",
       "396 -0.665431  0.167870 -0.977584 -0.874020 -1.061809  0.486728 -1.006273  \n",
       "397 -1.047044 -0.671453 -1.162517 -1.277949 -1.695760 -0.491759 -0.307659  \n",
       "\n",
       "[398 rows x 30 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizo los datos para ver si hay cambios en el modelo mediante StandardScaler\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "\n",
    "#NORMALIZACION STANDARDSCALER X_train\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = StandardScaler()\n",
    "#scaler.fit(X_train)\n",
    "x_scaler_train = scaler.fit_transform(X_train)\n",
    "\n",
    "#Solo hago fit los datos de entrenamiento \n",
    "\n",
    "x_scaler_train = pd.DataFrame(x_scaler_train)\n",
    "x_scaler_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.839863</td>\n",
       "      <td>1.515950</td>\n",
       "      <td>0.784706</td>\n",
       "      <td>0.708032</td>\n",
       "      <td>-0.912458</td>\n",
       "      <td>0.089657</td>\n",
       "      <td>0.336017</td>\n",
       "      <td>0.190091</td>\n",
       "      <td>-1.304589</td>\n",
       "      <td>-1.247963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.807798</td>\n",
       "      <td>1.661582</td>\n",
       "      <td>0.707814</td>\n",
       "      <td>0.651076</td>\n",
       "      <td>0.513983</td>\n",
       "      <td>0.984222</td>\n",
       "      <td>1.032834</td>\n",
       "      <td>0.864482</td>\n",
       "      <td>-0.639819</td>\n",
       "      <td>-0.254933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.754227</td>\n",
       "      <td>1.533022</td>\n",
       "      <td>-1.746353</td>\n",
       "      <td>-1.291094</td>\n",
       "      <td>-1.073814</td>\n",
       "      <td>-1.056770</td>\n",
       "      <td>-1.090460</td>\n",
       "      <td>-1.226448</td>\n",
       "      <td>0.212714</td>\n",
       "      <td>1.355139</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.437246</td>\n",
       "      <td>0.905777</td>\n",
       "      <td>-1.436048</td>\n",
       "      <td>-1.065603</td>\n",
       "      <td>-0.264771</td>\n",
       "      <td>-1.081895</td>\n",
       "      <td>-1.277949</td>\n",
       "      <td>-1.695760</td>\n",
       "      <td>0.258200</td>\n",
       "      <td>0.840222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.187330</td>\n",
       "      <td>-0.618133</td>\n",
       "      <td>0.244077</td>\n",
       "      <td>0.051519</td>\n",
       "      <td>1.365232</td>\n",
       "      <td>1.086229</td>\n",
       "      <td>0.911820</td>\n",
       "      <td>0.977139</td>\n",
       "      <td>1.293275</td>\n",
       "      <td>0.638523</td>\n",
       "      <td>...</td>\n",
       "      <td>0.495958</td>\n",
       "      <td>0.314784</td>\n",
       "      <td>0.546238</td>\n",
       "      <td>0.337898</td>\n",
       "      <td>2.426256</td>\n",
       "      <td>1.209183</td>\n",
       "      <td>0.880495</td>\n",
       "      <td>1.288490</td>\n",
       "      <td>1.106330</td>\n",
       "      <td>1.231270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.753405</td>\n",
       "      <td>-2.044920</td>\n",
       "      <td>-0.749959</td>\n",
       "      <td>-0.692689</td>\n",
       "      <td>-0.190855</td>\n",
       "      <td>-0.723288</td>\n",
       "      <td>-0.674365</td>\n",
       "      <td>-0.578683</td>\n",
       "      <td>-0.551585</td>\n",
       "      <td>-0.269374</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.693798</td>\n",
       "      <td>-1.583053</td>\n",
       "      <td>-0.682876</td>\n",
       "      <td>-0.630633</td>\n",
       "      <td>0.998541</td>\n",
       "      <td>-0.104134</td>\n",
       "      <td>-0.313440</td>\n",
       "      <td>-0.376919</td>\n",
       "      <td>0.190607</td>\n",
       "      <td>0.063068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.271625</td>\n",
       "      <td>-1.649810</td>\n",
       "      <td>-1.260729</td>\n",
       "      <td>-1.037605</td>\n",
       "      <td>0.409558</td>\n",
       "      <td>-0.758906</td>\n",
       "      <td>-0.740239</td>\n",
       "      <td>-0.713768</td>\n",
       "      <td>0.005638</td>\n",
       "      <td>0.828420</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.208233</td>\n",
       "      <td>-1.634661</td>\n",
       "      <td>-1.210408</td>\n",
       "      <td>-0.954748</td>\n",
       "      <td>0.029425</td>\n",
       "      <td>-0.884584</td>\n",
       "      <td>-0.871084</td>\n",
       "      <td>-0.778990</td>\n",
       "      <td>-0.720287</td>\n",
       "      <td>-0.348850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>-0.535894</td>\n",
       "      <td>-0.288875</td>\n",
       "      <td>-0.554688</td>\n",
       "      <td>-0.545820</td>\n",
       "      <td>-0.289192</td>\n",
       "      <td>-0.632858</td>\n",
       "      <td>-0.570104</td>\n",
       "      <td>-0.725868</td>\n",
       "      <td>-0.446164</td>\n",
       "      <td>-0.542436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.401821</td>\n",
       "      <td>-0.239585</td>\n",
       "      <td>-0.396291</td>\n",
       "      <td>-0.441567</td>\n",
       "      <td>0.219787</td>\n",
       "      <td>-0.242378</td>\n",
       "      <td>-0.170737</td>\n",
       "      <td>-0.395911</td>\n",
       "      <td>0.515697</td>\n",
       "      <td>-0.515266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>-0.321102</td>\n",
       "      <td>1.445220</td>\n",
       "      <td>-0.385742</td>\n",
       "      <td>-0.381092</td>\n",
       "      <td>-0.886142</td>\n",
       "      <td>-1.020783</td>\n",
       "      <td>-0.947575</td>\n",
       "      <td>-0.791312</td>\n",
       "      <td>-0.551585</td>\n",
       "      <td>-1.189747</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.391890</td>\n",
       "      <td>1.065595</td>\n",
       "      <td>-0.475378</td>\n",
       "      <td>-0.435104</td>\n",
       "      <td>-0.429174</td>\n",
       "      <td>-0.919145</td>\n",
       "      <td>-1.073208</td>\n",
       "      <td>-0.824041</td>\n",
       "      <td>-0.952034</td>\n",
       "      <td>-1.162802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>-0.772437</td>\n",
       "      <td>0.501346</td>\n",
       "      <td>-0.783749</td>\n",
       "      <td>-0.710815</td>\n",
       "      <td>-0.616060</td>\n",
       "      <td>-0.743588</td>\n",
       "      <td>-0.482312</td>\n",
       "      <td>-0.757479</td>\n",
       "      <td>-1.229288</td>\n",
       "      <td>0.307245</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.656059</td>\n",
       "      <td>0.611113</td>\n",
       "      <td>-0.675789</td>\n",
       "      <td>-0.618040</td>\n",
       "      <td>1.651829</td>\n",
       "      <td>-0.226040</td>\n",
       "      <td>0.153672</td>\n",
       "      <td>-0.477032</td>\n",
       "      <td>-0.110342</td>\n",
       "      <td>0.232779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>-0.244973</td>\n",
       "      <td>-1.337624</td>\n",
       "      <td>-0.260799</td>\n",
       "      <td>-0.323517</td>\n",
       "      <td>-0.890297</td>\n",
       "      <td>-0.374488</td>\n",
       "      <td>-0.488946</td>\n",
       "      <td>-0.519166</td>\n",
       "      <td>-0.739836</td>\n",
       "      <td>-0.988762</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.411752</td>\n",
       "      <td>-1.349986</td>\n",
       "      <td>-0.318621</td>\n",
       "      <td>-0.443058</td>\n",
       "      <td>-0.654148</td>\n",
       "      <td>0.081238</td>\n",
       "      <td>0.037123</td>\n",
       "      <td>-0.345266</td>\n",
       "      <td>-0.260012</td>\n",
       "      <td>-0.597649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>-0.220503</td>\n",
       "      <td>-0.686424</td>\n",
       "      <td>-0.248620</td>\n",
       "      <td>-0.292331</td>\n",
       "      <td>-1.754559</td>\n",
       "      <td>-0.605176</td>\n",
       "      <td>-0.131735</td>\n",
       "      <td>-0.534972</td>\n",
       "      <td>-1.474015</td>\n",
       "      <td>-0.671344</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.407780</td>\n",
       "      <td>-0.454340</td>\n",
       "      <td>-0.449015</td>\n",
       "      <td>-0.429139</td>\n",
       "      <td>-1.264171</td>\n",
       "      <td>-0.015532</td>\n",
       "      <td>0.239936</td>\n",
       "      <td>-0.373974</td>\n",
       "      <td>-1.367247</td>\n",
       "      <td>-0.428488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0    0.839863  1.515950  0.784706  0.708032 -0.912458  0.089657  0.336017   \n",
       "1   -1.754227  1.533022 -1.746353 -1.291094 -1.073814 -1.056770 -1.090460   \n",
       "2    0.187330 -0.618133  0.244077  0.051519  1.365232  1.086229  0.911820   \n",
       "3   -0.753405 -2.044920 -0.749959 -0.692689 -0.190855 -0.723288 -0.674365   \n",
       "4   -1.271625 -1.649810 -1.260729 -1.037605  0.409558 -0.758906 -0.740239   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "166 -0.535894 -0.288875 -0.554688 -0.545820 -0.289192 -0.632858 -0.570104   \n",
       "167 -0.321102  1.445220 -0.385742 -0.381092 -0.886142 -1.020783 -0.947575   \n",
       "168 -0.772437  0.501346 -0.783749 -0.710815 -0.616060 -0.743588 -0.482312   \n",
       "169 -0.244973 -1.337624 -0.260799 -0.323517 -0.890297 -0.374488 -0.488946   \n",
       "170 -0.220503 -0.686424 -0.248620 -0.292331 -1.754559 -0.605176 -0.131735   \n",
       "\n",
       "           7         8         9   ...        20        21        22  \\\n",
       "0    0.190091 -1.304589 -1.247963  ...  0.807798  1.661582  0.707814   \n",
       "1   -1.226448  0.212714  1.355139  ... -1.437246  0.905777 -1.436048   \n",
       "2    0.977139  1.293275  0.638523  ...  0.495958  0.314784  0.546238   \n",
       "3   -0.578683 -0.551585 -0.269374  ... -0.693798 -1.583053 -0.682876   \n",
       "4   -0.713768  0.005638  0.828420  ... -1.208233 -1.634661 -1.210408   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "166 -0.725868 -0.446164 -0.542436  ... -0.401821 -0.239585 -0.396291   \n",
       "167 -0.791312 -0.551585 -1.189747  ... -0.391890  1.065595 -0.475378   \n",
       "168 -0.757479 -1.229288  0.307245  ... -0.656059  0.611113 -0.675789   \n",
       "169 -0.519166 -0.739836 -0.988762  ... -0.411752 -1.349986 -0.318621   \n",
       "170 -0.534972 -1.474015 -0.671344  ... -0.407780 -0.454340 -0.449015   \n",
       "\n",
       "           23        24        25        26        27        28        29  \n",
       "0    0.651076  0.513983  0.984222  1.032834  0.864482 -0.639819 -0.254933  \n",
       "1   -1.065603 -0.264771 -1.081895 -1.277949 -1.695760  0.258200  0.840222  \n",
       "2    0.337898  2.426256  1.209183  0.880495  1.288490  1.106330  1.231270  \n",
       "3   -0.630633  0.998541 -0.104134 -0.313440 -0.376919  0.190607  0.063068  \n",
       "4   -0.954748  0.029425 -0.884584 -0.871084 -0.778990 -0.720287 -0.348850  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "166 -0.441567  0.219787 -0.242378 -0.170737 -0.395911  0.515697 -0.515266  \n",
       "167 -0.435104 -0.429174 -0.919145 -1.073208 -0.824041 -0.952034 -1.162802  \n",
       "168 -0.618040  1.651829 -0.226040  0.153672 -0.477032 -0.110342  0.232779  \n",
       "169 -0.443058 -0.654148  0.081238  0.037123 -0.345266 -0.260012 -0.597649  \n",
       "170 -0.429139 -1.264171 -0.015532  0.239936 -0.373974 -1.367247 -0.428488  \n",
       "\n",
       "[171 rows x 30 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NORMALIZACION STANDARDSCALER X_test\n",
    "\n",
    "#scaler_test.fit(X_test)\n",
    "#x_scaler_test = scaler_test.transform(X_test)\n",
    "x_scaler_test = scaler.transform(X_test)\n",
    "# No es necesario hacerle fit a los datos de test\n",
    "\n",
    "x_scaler_test = pd.DataFrame(x_scaler_test)\n",
    "x_scaler_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_sk = neighbors.KNeighborsClassifier(n_neighbors=1, p=1)\n",
    "clf_sk.fit(x_scaler_train,y_train)\n",
    "\n",
    "y_hat = clf_sk.predict(x_scaler_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de aciertos DATOS SIN NORMALIZAR: {0.9239766081871345}\n",
      "Tasa de aciertos DATOS NORMALIZADOS:  0.9415204678362573\n"
     ]
    }
   ],
   "source": [
    "print('Tasa de aciertos DATOS SIN NORMALIZAR:',  {accuracy})\n",
    "print('Tasa de aciertos DATOS NORMALIZADOS: ', accuracy_score(y_true=y_test, y_pred=y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Podemos observar que normalizando los datos obtenemos un mejor resultado, aunque esto va a depender del modelo que elijamos y además hay muchas maneras de hacerlo, en mi caso usé StandardScaler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Optimizar hiperparametros ¿cuánto mejora?\n",
    "\n",
    "### Voy a utilizar GridSearchCV de sklearn para encontrar los mejores hipermarámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 196 candidates, totalling 588 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 588 out of 588 | elapsed:    4.3s finished\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "    \n",
    "from sklearn.model_selection import GridSearchCV \n",
    "\n",
    "#Paso paramétros que obtuve de la documentacionde sklearn, los cuales son:\n",
    "#Cantidad de vecinos, el peso de los vecinos, la media de la distancia\n",
    "grid_params = {'n_neighbors': range(1,50), 'weights': ['uniform', 'distance'], 'metric':['euclidean' , 'manhattan']}\n",
    "\n",
    "#Ahora al GridSherch le paso los siguientes parámetros:\n",
    "#Modelo a utilizar, parametros grid para que pruebe, verbose muestra mensajes, \n",
    "#cv es la cantidad de folds y n_jobs es la cantidad de trabajo en paralelo (con -1 uso todos)\n",
    "gs = GridSearchCV(neighbors.KNeighborsClassifier(), grid_params, verbose = 1, cv = 3, n_jobs = -1 )\n",
    "\n",
    "#Utilizamos los datos sin normalizar\n",
    "gs_results = gs.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9522480443533076"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mejor puntaje\n",
    "gs_results.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(metric='manhattan', n_neighbors=6, weights='distance')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mejor estimador\n",
    "gs_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'manhattan', 'n_neighbors': 6, 'weights': 'distance'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mejores parametros\n",
    "gs_results.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 196 candidates, totalling 588 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 588 out of 588 | elapsed:    3.7s finished\n"
     ]
    }
   ],
   "source": [
    "# Ahora lo realizo con los datos normalizados\n",
    "\n",
    "grid_params = {'n_neighbors': range(1,50), 'weights': ['uniform', 'distance'], 'metric':['euclidean' , 'manhattan']}\n",
    "\n",
    "gs = GridSearchCV(neighbors.KNeighborsClassifier(), grid_params, verbose = 1, cv = 3, n_jobs = -1 )\n",
    "\n",
    "gs_results = gs.fit(x_scaler_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9749183564973039"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mejor puntaje\n",
    "gs_results.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(metric='manhattan', n_neighbors=2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mejor estimador\n",
    "gs_results.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con hiperparametros observamos que obtenemos aun un mejor resultado, y si utilizamos los datos normalizados tenemos el mejor score 97,4% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Aplicar modelos más complejos ¿mejora con modelos más complejos?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de aciertos:  0.9415204678362573\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "#Utilizo datos sin normalizar con RandomForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 10,criterion = \"entropy\", random_state=80)\n",
    "\n",
    "classifier.fit(X_train,y_train)\n",
    "# Predijo los resultados del conjunto de prueba\n",
    "y_hat = classifier.predict(X_test)\n",
    "print('Tasa de aciertos: ', accuracy_score(y_true=y_test, y_pred=y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de aciertos:  0.9415204678362573\n"
     ]
    }
   ],
   "source": [
    "#Utilizo datos normalizados con RandomForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 10,criterion = \"entropy\", random_state=80)\n",
    "\n",
    "classifier.fit(x_scaler_train,y_train)\n",
    "\n",
    "#Predijo los resultados del conjunto de prueba\n",
    "y_hat = classifier.predict(x_scaler_test)\n",
    "print('Tasa de aciertos: ', accuracy_score(y_true=y_test, y_pred=y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de aciertos:  0.9122807017543859\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/tree.html#tree\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html?highlight=decisiontree#sklearn.tree.DecisionTreeClassifier\n",
    "#Utilizo datos sin normalizar con Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion=\"entropy\", random_state=0)\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "#Predijo los resultados del conjunto de prueba\n",
    "y_hat = classifier.predict(X_test)\n",
    "print('Tasa de aciertos: ', accuracy_score(y_true=y_test, y_pred=y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de aciertos:  0.9122807017543859\n"
     ]
    }
   ],
   "source": [
    "#Utilizo datos normalizados con Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion=\"entropy\", random_state=0)\n",
    "classifier.fit(x_scaler_train,y_train)\n",
    "\n",
    "#Predijo los resultados del conjunto de prueba\n",
    "y_hat = classifier.predict(x_scaler_test)\n",
    "print('Tasa de aciertos: ', accuracy_score(y_true=y_test, y_pred=y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtenemos la misma tasa de aciertos en ambos modelos (RandomForest y Decision Tree), tanto con datos escalados como sin escalar, debido a que los modelos no tienen en cuenta si los datos estan escalados o no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Uso de kfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.74%\n"
     ]
    }
   ],
   "source": [
    "# Utilizo kfold como lo vimos en clase con los mejores parámetros encontrados cuando realizamos GridSearch \n",
    "# con los datos sin normalizar\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# n_splits es el numero de divisiones\n",
    "kf = KFold(n_splits=10, shuffle=True,random_state=80)\n",
    "\n",
    "# El siguiente for nos abstrae de tener que manejar explicitamente los subindices de los folds, \n",
    "# al dividir el conjunto de entrenamiento iterativamente. En cada una de sus iteraciones\n",
    "# obtenemos los subindices de todos los folds de entrenamiento y del fold de validacion de una\n",
    "# division en particular, de modo tal que todos los k folds sean al menos una vez usados para \n",
    "# entrenar el modelo\n",
    "\n",
    "accuracy = 0\n",
    "for train_index, validation_index in kf.split(X_train):\n",
    "    X_train_kf, X_validation_kf = X_train[train_index], X_train[validation_index]\n",
    "    y_train_kf, y_validation_kf = y_train[train_index], y_train[validation_index]\n",
    " \n",
    "    # desde aqui estamos trabajando con una division train-validation en particular\n",
    "    # es decir, por ejemplo, que train_index nos da todos los indices que componen a\n",
    "    # los folds que se usaran para entrenar el modelo en esta division. Usamos estos\n",
    "    # indices para obtener los X_train_kf y los y_train_kf. Lo mismo sucede con los\n",
    "    # indices usados para el fold de validación en esta division. Si se desea ver\n",
    "    # como cambian los indices en cada iteracion, hacer un print(validation_index)\n",
    "    #print(validation_index)\n",
    "    \n",
    "    model = neighbors.KNeighborsClassifier(metric='manhattan', n_neighbors=6, weights='distance')\n",
    "    model.fit(X_train_kf ,y_train_kf)\n",
    "    testPred = model.predict(X_validation_kf)\n",
    "    accuracy = accuracy + accuracy_score(y_validation_kf, testPred)\n",
    "    \n",
    "print(\"Accuracy: %.2f%%\" % (accuracy.mean()*10.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.22%\n"
     ]
    }
   ],
   "source": [
    "# Utilizo kfold mediante la libreria con los mejores parámetros encontrados cuando realizamos GridSearch \n",
    "# con los datos sin normalizar\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10)\n",
    "model_kfold = neighbors.KNeighborsClassifier(metric='manhattan', n_neighbors=6, weights='distance')\n",
    "results_kfold = model_selection.cross_val_score(model_kfold, X_train, y_train, cv=kfold)\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (results_kfold.mean()*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95      , 0.95      , 0.9       , 0.9       , 1.        ,\n",
       "       0.975     , 1.        , 0.975     , 0.94871795, 0.92307692])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Resultado que nos arroja cada fold del algoritmo\n",
    "results_kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.99%\n"
     ]
    }
   ],
   "source": [
    "# Utilizo kfold mediante la libreria con los mejores parámetros encontrados cuando realizamos GridSearch \n",
    "# con los datos normalizados y además utilizo los datos normalizados\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10)\n",
    "model_kfold = neighbors.KNeighborsClassifier(metric='manhattan', n_neighbors=2)\n",
    "results_kfold = model_selection.cross_val_score(model_kfold, x_scaler_train, y_train, cv=kfold)\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (results_kfold.mean()*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.975     , 1.        , 0.975     , 0.925     , 0.975     ,\n",
       "       0.95      , 0.975     , 0.975     , 1.        , 0.94871795])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Resultado que nos arroja cada fold del algoritmo\n",
    "results_kfold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podemos determinar que el mejor resultado lo obtenemos usando kfold mediante la libreria, utilizando los datos normalizados y los mejores parámetros encontrados en el GridSearch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
